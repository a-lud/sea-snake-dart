---
title: "Diversity statistics"
date: "`r Sys.Date()`"
output: 
    github_document:
        toc: true
---

This directory contains results relating to diversity statistics, both within
and between populations. The statistics are generated from the unfiltered
`Ipyrad` VCFs, with all filtering being applied by the package `snpR`.

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(
    echo = TRUE, message = FALSE, 
    warning = FALSE, error = FALSE,
    out.width = "100%"
)

suppressPackageStartupMessages({
    library(snpR)
    library(tidyverse)
    library(here)
    library(gt)
})

theme_set(theme_bw())

fs::dir_create(path = here("results", "diversity-statistics"))
```

## Accessory function

The standard `calc_genetic_distance()` function from `snpR` doesn't remove missing
data when using the `Nei` method (it does when using the `Edwards` method). As
such, the code below is taken from the `snpR` package, with one additional line
added to the `.get_dist()` function.
```{r}
al_calc_genetic_distances <- function(x, facets = NULL, method = "Edwards", interpolate = "bernoulli"){
    #============sanity checks=========
    msg <- character()
    
    if(!is.snpRdata(x)){
        stop("x is not a snpRdata object.\n")
    }
    
    good.methods <- c("Edwards", "Nei")
    if(!method %in% good.methods){
        msg <- c(msg, paste0("Provided method not supported. Supported methods: ", paste0(good.methods, collapse = " ")))
    }
    
    # get the allele frequencies if not already provided
    facets <- snpR:::.check.snpR.facet.request(x, facets, "none", T)
    snp_lev <- which(facets[[2]] == "snp" | facets[[2]] == ".base")
    snp_facets <- facets[[1]][snp_lev]
    all_facets <- facets[[1]]
    
    # pull out snp level facets, since these'll be done later.
    if(length(snp_lev) != length(facets[[1]])){
        if(length(snp_lev) > 0){
            facets <- facets[[1]][-snp_lev]
        }
        else{
            facets <- facets[[1]]
        }
        needed.facets <- snpR:::.check_calced_stats(x, facets, "allele_frequency_matrix")
        needed.facets <- facets[which(!unlist(needed.facets))]
        if(length(needed.facets) > 0){
            x <- tabulate_allele_frequency_matrix(x, needed.facets)
        }
        sample_facets_detected <- T
    }
    else{
        sample_facets_detected <- F
    }
    
    if(length(msg) > 0){
        stop(paste0(msg, collapse = "\n"))
    }
    
    # grab the data we are working with for sample specific facets
    y <- x
    if(sample_facets_detected){
        x <- snpR:::.get.snpR.stats(y, facets, "allele_frequency_matrix")
    }
    
    #=============run for facets with sample aggregation===============
    if(sample_facets_detected){
        out <- vector("list", length(x))
        names(out) <- names(x)
        # enter lapply hell--first level unlists once, second level runs the function if the values are matrices, unlists if not, third level can always run the function
        # the nice thing with this is that it should keep all of the names from x natively!
        out <- lapply(x, function(y){
            lapply(y, function(z) {
                if(is.matrix(z)){
                    al_get_dist(z, method = method)
                }
                else{
                    lapply(z, al_get_dist, method = method)
                }
            })
        })
    }
    
    # #============run for facets without sample aggregation (snp or .base level)
    if(length(snp_facets) > 0){
        # intialize output and get sn
        out_snp <- vector("list", length(snp_facets))
        names(out_snp) <- snp_facets
        sn <- format_snps(y, "sn", interpolate = interpolate)
        sn <- sn[,-c(1:(ncol(y@snp.meta) - 1))]
        
        # for each snp facet...
        for(i in 1:length(snp_facets)){
            if(snp_facets[i] == ".base"){
                out_snp[[i]] <- vector("list", 1)
                names(out_snp[[i]]) <- ".base"
                out_snp[[i]][[1]] <- list(stats::dist(t(sn)))
                names(out_snp[[i]][[1]]) <- method
                
            }
            else{
                # get tasks
                tasks <- .get.task.list(y, snp_facets[i])
                out_snp[[i]] <- vector("list", nrow(tasks))
                names(out_snp[[i]]) <- tasks[,4]
                snp_columns <- unlist(.split.facet(tasks[,3][1]))
                
                # run the tasks
                for(j in 1:nrow(tasks)){
                    t_snp_cols <- y@snp.meta[,snp_columns, drop = F]
                    t_snp_indices <- snpR:::.paste.by.facet(t_snp_cols, snp_columns, sep = "    ")
                    t_snp_indices <- which(t_snp_indices %in% tasks[j,4])
                    out_snp[[i]][[j]] <- list(stats::dist(t(sn[t_snp_indices,])))
                    names(out_snp[[i]][[j]]) <- method
                }
            }
            
        }
    }
    
    #============return=========
    if(exists("out") & exists("out_snp")){
        out <- c(out, out_snp)
    }
    else if(exists("out_snp")){
        out <- out_snp
    }
    
    y <- snpR:::.update_calced_stats(y, all_facets, paste0("genetic_distance_", method, "_", interpolate))
    if(method == "Edwards"){
        y <- snpR:::.update_citations(y, "Edwards1971", "genetic_distance", "Edwards' Angular Genetic Distance")
    }
    else if(method == "Nei"){
        y <- snpR:::.update_citations(y, "Nei1978", "genetic_distance", "Nei's genetic distance")
    }
    return(snpR:::.merge.snpR.stats(y, out, "genetic_distances"))
}

al_get_dist <- function(x, method = "Edwards"){
    #browser()
    if(method == "Edwards"){
        x <- x[,which(colSums(is.na(x)) == 0)] # remove anywhere where there is missing data!
        nloc <- ncol(x)
        x <- sqrt(as.matrix(x))
        am <- x%*%t(x)
        am <- 1 - (am / (nloc/2)) # can produce negative values, meaning an NaN distance measure
        diag(am) <- 0
        suppressWarnings(am <- sqrt(am))
        am <- stats::as.dist(am)
    }
    else if(method == "Nei"){
        # ADDED: Remove missing data (taken from above)
        x <- x[,which(colSums(is.na(x)) == 0)]
        d <- x %*% t(x)
        vec <- sqrt(diag(d))
        d <- d/vec[col(d)]
        d <- d/vec[row(d)]
        d <- -log(d)
        am <- stats::as.dist(d)
    }
    am <- list(am)
    names(am) <- method
    return(am)
}
```


## Load metadata and VCF files

Here we're simply loading the population-map files and storing them into the
object `meta`. This object is a named `list`, where each list element is a
dataframe.

```{r load-meta}
# Load data
meta <- fs::dir_ls(
    here("data", "popmaps"),
    glob = "*.txt"
) |>
    (\(x) set_names(x, str_remove(basename(x), "-.*")))() |>
    map(
        read_delim, 
        delim = " ", col_names = c("sample", "population"), col_types = cols()
    )

# Example of the Aipysurus tibble
meta$ALA |>
    head() |>
    gt() |>
    as_raw_html()
```

Next we load the VCF files into `R` as `snpRdata` objects. Similarly, we load
each species' file separately and store it in a list. Filtering is applied here
so we don't have to pre-filter our data ahead of time.

```{r load-vcfs, results='hide'}
# List VCF files and name vector elements
vcfs <- fs::dir_ls(
    here("results", "ipyrad"),
    glob = "*stringent.vcf.gz",
    recurse = TRUE
) |>
    (\(x) set_names(x, str_remove(basename(x), "-stringent.*")))()

# Load each VCF file separately (with corresponding metadata)
vcfs <- imap(vcfs, \(v, i) {
    tmp_vcf <- read_vcf(
        file = v, 
        sample.meta = meta[[i]]
    )
    
    filter_snps(
        tmp_vcf,
        remove_garbage = 0.2,
        min_ind = 0.8,
        min_loci = 0.8,
        re_run = TRUE
    )
})
```

## Calculate statistics

Next we'll calculate a range of diversity statistics. The program `snpR` has a
really convenient function `calc_basic_snp_stats()` which practically estimates
all the statistics we want.

Below we estimate `pi`, `ho`, `he`, pairwise $\text{F}_\text{ST}$, $\text{F}_\text{is}$,
and HWE. We estimate all statistics by population.

```{r calc-basic-stats}
# Run calc_basic_snp_stats on each VCF object
basic_stats <- map(
    vcfs, 
    calc_basic_snp_stats, 
    # Below are aguments to 'calc_basic_snp_stats'
    facets = "population", 
    fst.method = "WC"
)

# Get the statistics as list of tables
basic_stats_list_tables <- map(
    basic_stats, 
    get.snpR.stats,
    facets = "population", 
    stats = c("pi", "hwe", "ho", "he", "fis", "fst") 
)

# Genetic distance
between_distance <- map(
    vcfs,
    al_calc_genetic_distances,
    facets = "population",
    method = "Nei"
)

between_distance_list_tables <- map(
    between_distance,
    get.snpR.stats,
    facets = "population", 
    stats = "genetic_distance"
)


```

## External calculation of $\pi$: Why invariant data matters

Nucleotide diversity calculated across multiple sites is given by the equation
below.

$$
\pi = \frac{1}{L} \sum_{i=1}^{L} \left( \frac{2n_i(n_i-1)}{N(N-1)} \right)
$$

An important component of this equation is $\frac{1}{L}$. This is the
reciprocal of the **total** sequence length/number of sites being considered. We
know that most sites in the genome don't vary - e.g. in humans we have approximately
**one SNP per kilobase (1kb)**. Below is a schematic showing SNPs along a
sequence of length 10.

```
5' -  1 2 3 4 5 6 7 8 9 10 - 3'  Position
5' -  A T A C C G T A A C  - 3'  Seq1
5' -  A T A G C G T A A C  - 3'  Seq2
5' -  A T A G C G T A C C  - 3'  Seq3
5' -  A T A C C G T A A C  - 3'  Seq4
```

Using the example above, if we considered **only** SNP positions, the length
would equal 2 ($L = \text{2}$). This is not the actual sequence length, but if
we only provided variable sites to the equation, the program calculating $\pi$
wont know that and will simply take the number of variants as the length. As
the number of variant sites is **much shorter** than the actual length, the
value of $\pi$ is scaled incorrectly, resulting in a higher estimate due to a
small value of $L$.

$$
\pi = \frac{1}{2} \times \frac{7}{6} \approx 0.5833
$$

- Length ($L$) = 2 (2 variant sites)
- Total number of differences ($\sum \text{d}_{ij}$) = 7
- Total number of comparisons $(\frac{4}{2})$ = 6 (1..2, 1..3, 1..4, 2..3 etc...)

Instead, we should calculate length ($L$) using both variant **and** invariant
sites. The variant sites will still be used to calculate divergence, but the
combined length is used to properly scale the level of differentiation. Using
the correct length ($L = \text{10}$) would scale the value of $\pi$ down, resulting
in a more accurate reflection of divergence within the population.

$$
\pi = \frac{1}{10} \times \frac{7}{6} \approx 0.1167
$$

The program `pixy` calculates $\pi$ the second way when given a VCF with both
variant and invariant data. The authors of `Ipyrad` wrote a script that can
return an **all-sites** VCF file from the `.loci` files. I've passed that to
`pixy` to get a more accurate estimation of $\pi$ in each population.

```{r}
pixy_pi <- fs::dir_ls(
    here("results"),
    glob = "*pi.txt",
    recurse = TRUE
) |>
    read_tsv(col_types = cols(), id = "species") |>
    mutate(species = str_remove(basename(species), "_.*")) |>
    summarise(
        pixy_pi = sum(count_diffs)/sum(count_comparisons),
        .by = c(species, pop)
    ) |>
    rename(subfacet = pop)
```

The $\pi$ estimates are included in the next table.

## Within population statistics

Below we simply extract the weighted averages for each population. The table
contains four relevant columns - weighted means for nucleotide diversity, 
observed heterozygosity, expected heterozygosity and `Fis`. I've appended the
`pixy` $\pi$ estimates so you can compare the impact of calculating nucleotide
diversity with and without invariant sites.

```{r within-statistics}
l_ala <- length(unique(meta$ALA$population))
l_hma <- length(unique(meta$HMA$population))
l_hst <- length(unique(meta$HST$population))

within <- basic_stats_list_tables |>
    imap(
        \(x, i) {
            x |> 
                pluck("weighted.means") |> 
                as_tibble() |> 
                filter(is.na(weighted_mean_fst)) |>
                select(-c(snp.facet, snp.subfacet, weighted_mean_fst, mean_fst)) |>
                left_join(
                    meta[[i]] |> summarise(n_samples = n(), .by = population),
                    by = join_by(subfacet == population)
                )
            
        }) |>
    list_rbind(names_to = "species") |>
    left_join(pixy_pi)

# Write to file
within |>
    (\(x) split(x, x$species))() |>
    iwalk(\(x, i) {
        x |>
            select(
                species, 
                population = subfacet, 
                n_samples, 
                pixy_pi, 
                everything(),
                -facet
            ) |>
            write_csv(
                file = here("results", "diversity-statistics", glue::glue("{i}-within-stats.csv"))
            )
    })

# Example of output
within |>
    select(subfacet, n_samples, pixy_pi, everything(), -facet) |>
    gt(groupname_col = "species") |>
    fmt_number(
        columns = c(starts_with("weighted_"), "pixy_pi"), 
        n_sigfig = 3
    ) |>
    cols_label(
        subfacet = ""
    ) |>
    as_raw_html()
```

I've left the $\pi$ calculation based on **just SNPs** in the table. We can see
that the values are much higher than the `pixy` estimations.

# Between population statistics

Lastly we have our $\text{F}_\text{ST}$ measures. I've separated out the upper
matricies for each of the three species.

```{r get-fst}
# nei_distance_matrix 
nei_dist_matrix <- between_distance_list_tables |>
    map(
        \(i)
        i |>
            pluck("population") |>
            pluck(".base") |>
            pluck("Nei")
)

fst_upper_matrix <- basic_stats_list_tables |>
    map(
        \(i) 
        i |> 
            pluck("fst.matrix") |>
            pluck("population") |>
            as_tibble()
    )
```

```{r write-fst, echo=FALSE}
# Write FST matricies to file
iwalk(fst_upper_matrix, \(x, i) {
    x |>
        write_csv(
            file = here("results", "diversity-statistics", glue::glue("{i}-fst.csv")),
            na = ""
        )
})
```

### *Aipysurus laevis*

```{r FST-ALA}
fst_upper_matrix$ALA |>
    gt() |>
    fmt_missing(missing_text = "") |>
    cols_label(p1 = "") |>
    fmt_number(n_sigfig = 3) |>
    as_raw_html()
```

### *Hydrophis major*

```{r FST-HMA}
fst_upper_matrix$HMA |>
    gt() |>
    fmt_missing(missing_text = "") |>
    cols_label(p1 = "") |>
    fmt_number(n_sigfig = 3) |>
    as_raw_html()
```

### *Hydrophis stokesii*

```{r}
fst_upper_matrix$HST |>
    gt() |>
    fmt_missing(missing_text = "") |>
    cols_label(p1 = "") |>
    fmt_number(n_sigfig = 3) |>
    as_raw_html()
```


