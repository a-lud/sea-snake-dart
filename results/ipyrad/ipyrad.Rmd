---
title: "Sequence QC"
date: "`r Sys.Date()`"
output: 
    github_document:
        toc: true
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(
    echo = TRUE, message = FALSE, 
    warning = FALSE, error = FALSE,
    fig.height = 10, fig.width = 10, fig.dpi=300,
    out.width = "100%"
)

suppressPackageStartupMessages({
    library(tidyverse)
    library(patchwork)
    library(here)
    library(gt)
})

theme_set(theme_bw())

pops <- fs::dir_ls(here("data", "popmaps"), glob = "*.txt") |>
    read_delim(
        delim = " ", 
        col_names = c("sample", "population"), 
        col_types = cols(), 
        id = "species"
    ) |>
    mutate(species = str_remove(basename(species), "-.*"))

# Loading total and post QC read counts
qc <- read_csv(
    here("results", "qc", "raw_trimmed_reads_bases.csv"),
    col_types = cols()
)
```

# Ipyrad summary

The code combines the read summary statistics from the QC pipeline with the
summary results generated by `Ipyrad`. Summary tables for each species are written
to file as CSVs so they can be included as summary tables.

```{r}
stats <- fs::dir_ls(path = here("results", "ipyrad"), glob = "*stats.txt", recurse = TRUE) |>
    (\(x) set_names(x, str_remove(basename(x), "-stringent_stats.txt")))() |>
    map(\(x) {
        lines <- x |>
            read_lines(skip_empty_rows = TRUE)

        start <- grep(x = lines, "## Final Sample stats summary") + 1
        end <- grep(x = lines, "## Alignment matrix statistics:") - 1

        keep <- lines[start:end]
        keep <- keep[1] |>
            trimws(which = "left") |>
            strsplit(split = " ") |>
            unlist()
        colnames <- c("sample", keep[nzchar(keep)])

        tibble( col = lines[(start + 1):end] ) |>
            separate(col = col, into = colnames, sep = "\\s+", convert = TRUE) |>
            select(-state) |>
            left_join(qc, by = join_by(sample == file)) |>
            select(
                Species, Region, Sample = sample,
                reads_raw = num_seqs_Raw,
                reads_sum_len_raw = sum_len_Raw,
                reads_qc = reads_raw,
                reads_sum_len_qc = sum_len_Trimmed,
                reads_ipyrad = reads_passed_filter,
                everything(),
                -num_seqs_Trimmed
            )
    })

# Write summary table to file for each species
stats |>
    iwalk(\(x, i) {
        x |>
            write_csv(
                file = here(
                    "results",
                    "ipyrad",
                    glue::glue("{i}-stringent_outfiles"),
                    glue::glue("{i}-stringent-stats.csv")
                )
            )
    })

# Combine list and preview table
stats <- stats |>
    list_rbind(names_to = "Species")

stats |>
    head() |>
    gt() |>
    fmt_number(
        columns = c(starts_with("reads"), starts_with("refseq"), starts_with("clusters"), loci_in_assembly),
        sep_mark = ",", 
        drop_trailing_zeros = TRUE
    ) |>
    fmt_number(
        columns = c(hetero_est, error_est), 
        n_sigfig = 2
    ) |>
    as_raw_html()
```

## Data summary

After running `Ipyrad`, we get a range of summary information detailing how much
of our QC'd data is actually used in the analysis. The figures below broadly
summarise this information.

### Read summary

The amount of reads lost over the course of the project is shown below for each
species. The groupings are as follows:

- **reads_raw**: Number of reads received by DaRT
- **reads_qc**: Reads remaining after QC pipeline (`bbduk`, `Kraken2`, `fastp`)
- **reads_ipyrad**: Number of reads remaining after `Ipyrad` applies its own filters
- **refseq_mapped_reads**: Number of reads that could map to the reference genome

```{r}
# Data filtration (QC)
stats |>
    pivot_longer(
        names_to = "measure", 
        values_to = "values", 
        cols = c(reads_raw, reads_qc, reads_ipyrad, refseq_mapped_reads)
    ) |>
    mutate(
        Species = forcats::fct_inorder(Species),
        measure = forcats::fct_inorder(measure)
    ) |>
    ggplot(
        aes(
            x = Species, y = values, 
            fill = measure
        )
    ) +
    geom_boxplot() +
    scale_y_continuous(
        name = "Read count",
        labels = scales::number_format(scale = 1e-6, suffix = "M"),
        limits = c(0, 2.5e6),
        breaks = seq(0, 2.5e6, 200e3),
    ) +
    scale_fill_brewer(palette = "Set2") +
    guides(fill = guide_legend(
        keyheight = 2.5,
        keywidth = 2
    )) +
    labs(
        title = "Reads lost to filtering"
    ) +
    theme(
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 16, face = "bold"),
        axis.title.x = element_blank(),
        axis.text = element_text(size = 12),
        legend.position = "bottom",
        legend.title = element_blank(),
        legend.text = element_text(size = 12)
    )
```

Notably, the *H. stokesii* samples have quite a large spread in their read counts
compared to the other two species.

## Outliers: Too few loci

The figure below shows the Z-normalised `loci_in_assembly` vs `refseq_mapped_reads`.
The expected relationship is that samples with high mapping rates to the reference
genome will have more loci. Samples whose loci number are more than two standard
deviations from their species' mean are labelled. The Z-normalisation was applied
within each species.

Samples with low loci counts are likely to be limiting factors in downstream
analysis - samples with few loci are always going to cause issues when filtering
on percent-missing etc... Therefore, these samples are likely candiates that
should be removed.

```{r}
z_data <- stats |>
    mutate(
        Z_loci_in_assembly = scale(loci_in_assembly)[,1], 
        Z_refseq_mapped_reads = scale(refseq_mapped_reads)[,1],
        .by = Species
    )

z_data |>
    ggplot(
        aes(
            x = Z_loci_in_assembly, 
            y = Z_refseq_mapped_reads, 
            colour = Species
        )
    ) +
    geom_point(size = 2) +
    geom_vline(xintercept = -2, linetype = "dashed", colour = "red") +
    geom_hline(yintercept = -2, linetype = "dashed", colour = "grey70") +
    scale_x_continuous(
        breaks = seq(-3, 3, 1),
        limits = c(-3.5, 3.5)
    ) +
    scale_y_continuous(
        breaks = seq(-3, 3, 1),
        limits = c(-3.5, 3.5)
    ) +
    scale_colour_brewer(
        palette = "Set2"
    ) +
    guides(colour = guide_legend(override.aes = list(size=3))) +
    ggrepel::geom_label_repel(
        mapping = aes(label = Sample, colour = Species),
        data = z_data |> filter(Z_loci_in_assembly <= -2),
        show.legend = FALSE
    ) +
    labs(
        x = "Loci in assembly\n(Z-normalised)",
        y = "Reference mapped reads\n(Z-normalised)"
    ) +
    theme(
        axis.title = element_text(size = 16, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position.inside = c(0.9, 0.1),
        legend.position = "inside",
        legend.title = element_text(size = 14, face = "bold", hjust = 0.5),
        legend.text = element_text(size = 12)
    )
```

Note that in the figure above, we only label samples that had extremely low loci
counts. While some samples had lower than average mapping rates (points below the
light-grey dashed line), their loci number are still somewhat similar to the average.
